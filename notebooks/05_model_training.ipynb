{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training and Evaluation\n",
        "\n",
        "Train and evaluate all models: baseline, XGBoost, neural network, and ensemble.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.insert(0, str(Path().resolve().parent.parent / \"src\"))\n",
        "\n",
        "from src.data.preprocess import load_match_data, extract_team_compositions, train_val_test_split\n",
        "from src.features.team_composition import TeamCompositionFeatureExtractor\n",
        "from src.models.baseline import BaselineModel\n",
        "from src.models.xgboost_model import XGBoostModel\n",
        "from src.models.neural_net import NeuralNetModel\n",
        "from src.models.ensemble import EnsembleModel\n",
        "import numpy as np\n",
        "\n",
        "# Load data and extract features\n",
        "data_path = Path().resolve().parent.parent / \"data\" / \"raw\" / \"synthetic_matches.csv\"\n",
        "df = load_match_data(data_path)\n",
        "team1_list, team2_list, y = extract_team_compositions(df)\n",
        "\n",
        "# Load embeddings\n",
        "embeddings_path = Path().resolve().parent.parent / \"data\" / \"embeddings\" / \"hero_embeddings.npy\"\n",
        "embeddings = np.load(embeddings_path) if embeddings_path.exists() else None\n",
        "\n",
        "# Extract features\n",
        "extractor = TeamCompositionFeatureExtractor(embeddings=embeddings)\n",
        "X = np.array([extractor.extract_feature_vector(t1, t2) for t1, t2 in zip(team1_list, team2_list)])\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y)\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "# Train models\n",
        "baseline = BaselineModel()\n",
        "baseline.train(X_train, y_train)\n",
        "\n",
        "xgboost = XGBoostModel(n_estimators=100)\n",
        "xgboost.train(X_train, y_train, X_val, y_val)\n",
        "\n",
        "neural_net = NeuralNetModel(input_dim=X.shape[1], epochs=20)\n",
        "neural_net.train(X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Create ensemble\n",
        "ensemble = EnsembleModel(\n",
        "    xgboost_model=xgboost,\n",
        "    neural_net_model=neural_net,\n",
        "    xgboost_weight=0.6,\n",
        "    neural_net_weight=0.4\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "from src.utils.metrics import calculate_metrics\n",
        "\n",
        "test_pred = ensemble.predict(X_test)\n",
        "test_proba = ensemble.predict_proba(X_test)[:, 1]\n",
        "metrics = calculate_metrics(y_test, test_pred, test_proba)\n",
        "\n",
        "print(f\"Test Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"Test F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "# Save models\n",
        "models_dir = Path().resolve().parent.parent / \"models\"\n",
        "baseline.save(models_dir / \"baseline.pkl\")\n",
        "xgboost.save(models_dir / \"xgboost_model.pkl\")\n",
        "neural_net.save(models_dir / \"neural_net_model.pt\")\n",
        "ensemble.save(models_dir / \"ensemble\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
